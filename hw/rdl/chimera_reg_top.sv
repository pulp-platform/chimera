// Copyright 2025 ETH Zurich and University of Bologna.
// Licensed under the Apache License, Version 2 0, see LICENSE for details.
// SPDX-License-Identifier: Apache-2.0

// Generated by PeakRDL-regblock - A free and open-source SystemVerilog generator
//  https://github.com/SystemRDL/PeakRDL-regblock

module chimera_reg_top (
  input wire clk,
  input wire arst_n,

  input  wire         s_apb_psel,
  input  wire         s_apb_penable,
  input  wire         s_apb_pwrite,
  input  wire  [ 2:0] s_apb_pprot,
  input  wire  [ 6:0] s_apb_paddr,
  input  wire  [31:0] s_apb_pwdata,
  input  wire  [ 3:0] s_apb_pstrb,
  output logic        s_apb_pready,
  output logic [31:0] s_apb_prdata,
  output logic        s_apb_pslverr,

  output chimera_reg_pkg::chimera_regs__out_t hwif_out
);

  //--------------------------------------------------------------------------
  // CPU Bus interface logic
  //--------------------------------------------------------------------------
  logic        cpuif_req;
  logic        cpuif_req_is_wr;
  logic [ 6:0] cpuif_addr;
  logic [31:0] cpuif_wr_data;
  logic [31:0] cpuif_wr_biten;
  logic        cpuif_req_stall_wr;
  logic        cpuif_req_stall_rd;

  logic        cpuif_rd_ack;
  logic        cpuif_rd_err;
  logic [31:0] cpuif_rd_data;

  logic        cpuif_wr_ack;
  logic        cpuif_wr_err;

  // Request
  logic        is_active;
  always_ff @(posedge clk or negedge arst_n) begin
    if (~arst_n) begin
      is_active       <= '0;
      cpuif_req       <= '0;
      cpuif_req_is_wr <= '0;
      cpuif_addr      <= '0;
      cpuif_wr_data   <= '0;
      cpuif_wr_biten  <= '0;
    end else begin
      if (~is_active) begin
        if (s_apb_psel) begin
          is_active       <= '1;
          cpuif_req       <= '1;
          cpuif_req_is_wr <= s_apb_pwrite;
          cpuif_addr      <= {s_apb_paddr[6:2], 2'b0};
          cpuif_wr_data   <= s_apb_pwdata;
          for (int i = 0; i < 4; i++) begin
            cpuif_wr_biten[i*8+:8] <= {8{s_apb_pstrb[i]}};
          end
        end
      end else begin
        cpuif_req <= '0;
        if (cpuif_rd_ack || cpuif_wr_ack) begin
          is_active <= '0;
        end
      end
    end
  end

  // Response
  assign s_apb_pready  = cpuif_rd_ack | cpuif_wr_ack;
  assign s_apb_prdata  = cpuif_rd_data;
  assign s_apb_pslverr = cpuif_rd_err | cpuif_wr_err;

  logic cpuif_req_masked;

  // Read & write latencies are balanced. Stalls not required
  assign cpuif_req_stall_rd = '0;
  assign cpuif_req_stall_wr = '0;
  assign cpuif_req_masked = cpuif_req
                            & !(!cpuif_req_is_wr & cpuif_req_stall_rd)
                            & !(cpuif_req_is_wr & cpuif_req_stall_wr);

  //--------------------------------------------------------------------------
  // Address Decode
  //--------------------------------------------------------------------------
  typedef struct {
    logic snitch_boot_addr;
    logic snitch_configurable_boot_addr;
    logic snitch_intr_handler_addr;
    logic snitch_cluster_return[5];
    logic reset_cluster[5];
    logic cluster_clk_gate_en[5];
    logic wide_mem_cluster_bypass[5];
    logic cluster_busy[5];
  } decoded_reg_strb_t;
  decoded_reg_strb_t        decoded_reg_strb;
  logic                     decoded_req;
  logic                     decoded_req_is_wr;
  logic              [31:0] decoded_wr_data;
  logic              [31:0] decoded_wr_biten;

  always_comb begin
    decoded_reg_strb.snitch_boot_addr              = cpuif_req_masked & (cpuif_addr == 7'h0);
    decoded_reg_strb.snitch_configurable_boot_addr = cpuif_req_masked & (cpuif_addr == 7'h4);
    decoded_reg_strb.snitch_intr_handler_addr      = cpuif_req_masked & (cpuif_addr == 7'h8);
    for (int i0 = 0; i0 < 5; i0++) begin
      decoded_reg_strb.snitch_cluster_return[i0] = cpuif_req_masked & (cpuif_addr == 7'hc + (7)'(i0) * 7'h4);
    end
    for (int i0 = 0; i0 < 5; i0++) begin
      decoded_reg_strb.reset_cluster[i0] = cpuif_req_masked & (cpuif_addr == 7'h20 + (7)'(i0) * 7'h4);
    end
    for (int i0 = 0; i0 < 5; i0++) begin
      decoded_reg_strb.cluster_clk_gate_en[i0] = cpuif_req_masked & (cpuif_addr == 7'h34 + (7)'(i0) * 7'h4);
    end
    for (int i0 = 0; i0 < 5; i0++) begin
      decoded_reg_strb.wide_mem_cluster_bypass[i0] = cpuif_req_masked & (cpuif_addr == 7'h48 + (7)'(i0) * 7'h4);
    end
    for (int i0 = 0; i0 < 5; i0++) begin
      decoded_reg_strb.cluster_busy[i0] = cpuif_req_masked & (cpuif_addr == 7'h5c + (7)'(i0) * 7'h4);
    end
  end

  // Pass down signals to next stage
  assign decoded_req       = cpuif_req_masked;
  assign decoded_req_is_wr = cpuif_req_is_wr;
  assign decoded_wr_data   = cpuif_wr_data;
  assign decoded_wr_biten  = cpuif_wr_biten;

  //--------------------------------------------------------------------------
  // Field logic
  //--------------------------------------------------------------------------
  typedef struct {
    struct {
      struct {
        logic [31:0] next;
        logic        load_next;
      } SNITCH_BOOT_ADDR;
    } snitch_boot_addr;
    struct {
      struct {
        logic [31:0] next;
        logic        load_next;
      } SNITCH_CONFIGURABLE_BOOT_ADDR;
    } snitch_configurable_boot_addr;
    struct {
      struct {
        logic [31:0] next;
        logic        load_next;
      } SNITCH_INTR_HANDLER_ADDR;
    } snitch_intr_handler_addr;
    struct {
      struct {
        logic [31:0] next;
        logic        load_next;
      } SNITCH_CLUSTER_RETURN;
    } snitch_cluster_return[5];
    struct {
      struct {
        logic next;
        logic load_next;
      } RESET_CLUSTER;
    } reset_cluster[5];
    struct {
      struct {
        logic next;
        logic load_next;
      } CLUSTER_CLK_GATE_EN;
    } cluster_clk_gate_en[5];
    struct {
      struct {
        logic next;
        logic load_next;
      } WIDE_MEM_CLUSTER_BYPASS;
    } wide_mem_cluster_bypass[5];
    struct {
      struct {
        logic next;
        logic load_next;
      } CLUSTER_BUSY;
    } cluster_busy[5];
  } field_combo_t;
  field_combo_t field_combo;

  typedef struct {
    struct {struct {logic [31:0] value;} SNITCH_BOOT_ADDR;} snitch_boot_addr;
    struct {
      struct {logic [31:0] value;} SNITCH_CONFIGURABLE_BOOT_ADDR;
    } snitch_configurable_boot_addr;
    struct {struct {logic [31:0] value;} SNITCH_INTR_HANDLER_ADDR;} snitch_intr_handler_addr;
    struct {struct {logic [31:0] value;} SNITCH_CLUSTER_RETURN;} snitch_cluster_return[5];
    struct {struct {logic value;} RESET_CLUSTER;} reset_cluster[5];
    struct {struct {logic value;} CLUSTER_CLK_GATE_EN;} cluster_clk_gate_en[5];
    struct {struct {logic value;} WIDE_MEM_CLUSTER_BYPASS;} wide_mem_cluster_bypass[5];
    struct {struct {logic value;} CLUSTER_BUSY;} cluster_busy[5];
  } field_storage_t;
  field_storage_t field_storage;

  // Field: chimera_regs.snitch_boot_addr.SNITCH_BOOT_ADDR
  always_comb begin
    automatic logic [31:0] next_c;
    automatic logic        load_next_c;
    next_c      = field_storage.snitch_boot_addr.SNITCH_BOOT_ADDR.value;
    load_next_c = '0;
    if (decoded_reg_strb.snitch_boot_addr && decoded_req_is_wr) begin  // SW write
      next_c = (field_storage.snitch_boot_addr.SNITCH_BOOT_ADDR.value & ~decoded_wr_biten[31:0]) | (decoded_wr_data[31:0] & decoded_wr_biten[31:0]);
      load_next_c = '1;
    end
    field_combo.snitch_boot_addr.SNITCH_BOOT_ADDR.next      = next_c;
    field_combo.snitch_boot_addr.SNITCH_BOOT_ADDR.load_next = load_next_c;
  end
  always_ff @(posedge clk or negedge arst_n) begin
    if (~arst_n) begin
      field_storage.snitch_boot_addr.SNITCH_BOOT_ADDR.value <= 32'hbadcab1e;
    end else begin
      if (field_combo.snitch_boot_addr.SNITCH_BOOT_ADDR.load_next) begin
        field_storage.snitch_boot_addr.SNITCH_BOOT_ADDR.value <= field_combo.snitch_boot_addr.SNITCH_BOOT_ADDR.next;
      end
    end
  end
  assign hwif_out.snitch_boot_addr.SNITCH_BOOT_ADDR.value = field_storage.snitch_boot_addr.SNITCH_BOOT_ADDR.value;
  // Field: chimera_regs.snitch_configurable_boot_addr.SNITCH_CONFIGURABLE_BOOT_ADDR
  always_comb begin
    automatic logic [31:0] next_c;
    automatic logic        load_next_c;
    next_c      = field_storage.snitch_configurable_boot_addr.SNITCH_CONFIGURABLE_BOOT_ADDR.value;
    load_next_c = '0;
    if (decoded_reg_strb.snitch_configurable_boot_addr && decoded_req_is_wr) begin  // SW write
      next_c = (field_storage.snitch_configurable_boot_addr.SNITCH_CONFIGURABLE_BOOT_ADDR.value & ~decoded_wr_biten[31:0]) | (decoded_wr_data[31:0] & decoded_wr_biten[31:0]);
      load_next_c = '1;
    end
    field_combo.snitch_configurable_boot_addr.SNITCH_CONFIGURABLE_BOOT_ADDR.next = next_c;
    field_combo.snitch_configurable_boot_addr.SNITCH_CONFIGURABLE_BOOT_ADDR.load_next = load_next_c;
  end
  always_ff @(posedge clk or negedge arst_n) begin
    if (~arst_n) begin
      field_storage.snitch_configurable_boot_addr.SNITCH_CONFIGURABLE_BOOT_ADDR.value <= 32'h30000000;
    end else begin
      if (field_combo.snitch_configurable_boot_addr.SNITCH_CONFIGURABLE_BOOT_ADDR.load_next) begin
        field_storage.snitch_configurable_boot_addr.SNITCH_CONFIGURABLE_BOOT_ADDR.value <= field_combo.snitch_configurable_boot_addr.SNITCH_CONFIGURABLE_BOOT_ADDR.next;
      end
    end
  end
  assign hwif_out.snitch_configurable_boot_addr.SNITCH_CONFIGURABLE_BOOT_ADDR.value = field_storage.snitch_configurable_boot_addr.SNITCH_CONFIGURABLE_BOOT_ADDR.value;
  // Field: chimera_regs.snitch_intr_handler_addr.SNITCH_INTR_HANDLER_ADDR
  always_comb begin
    automatic logic [31:0] next_c;
    automatic logic        load_next_c;
    next_c      = field_storage.snitch_intr_handler_addr.SNITCH_INTR_HANDLER_ADDR.value;
    load_next_c = '0;
    if (decoded_reg_strb.snitch_intr_handler_addr && decoded_req_is_wr) begin  // SW write
      next_c = (field_storage.snitch_intr_handler_addr.SNITCH_INTR_HANDLER_ADDR.value & ~decoded_wr_biten[31:0]) | (decoded_wr_data[31:0] & decoded_wr_biten[31:0]);
      load_next_c = '1;
    end
    field_combo.snitch_intr_handler_addr.SNITCH_INTR_HANDLER_ADDR.next      = next_c;
    field_combo.snitch_intr_handler_addr.SNITCH_INTR_HANDLER_ADDR.load_next = load_next_c;
  end
  always_ff @(posedge clk or negedge arst_n) begin
    if (~arst_n) begin
      field_storage.snitch_intr_handler_addr.SNITCH_INTR_HANDLER_ADDR.value <= 32'hbadcab1e;
    end else begin
      if (field_combo.snitch_intr_handler_addr.SNITCH_INTR_HANDLER_ADDR.load_next) begin
        field_storage.snitch_intr_handler_addr.SNITCH_INTR_HANDLER_ADDR.value <= field_combo.snitch_intr_handler_addr.SNITCH_INTR_HANDLER_ADDR.next;
      end
    end
  end
  assign hwif_out.snitch_intr_handler_addr.SNITCH_INTR_HANDLER_ADDR.value = field_storage.snitch_intr_handler_addr.SNITCH_INTR_HANDLER_ADDR.value;
  for (genvar i0 = 0; i0 < 5; i0++) begin
    // Field: chimera_regs.snitch_cluster_return[].SNITCH_CLUSTER_RETURN
    always_comb begin
      automatic logic [31:0] next_c;
      automatic logic        load_next_c;
      next_c      = field_storage.snitch_cluster_return[i0].SNITCH_CLUSTER_RETURN.value;
      load_next_c = '0;
      if (decoded_reg_strb.snitch_cluster_return[i0] && decoded_req_is_wr) begin  // SW write
        next_c = (field_storage.snitch_cluster_return[i0].SNITCH_CLUSTER_RETURN.value & ~decoded_wr_biten[31:0]) | (decoded_wr_data[31:0] & decoded_wr_biten[31:0]);
        load_next_c = '1;
      end
      field_combo.snitch_cluster_return[i0].SNITCH_CLUSTER_RETURN.next      = next_c;
      field_combo.snitch_cluster_return[i0].SNITCH_CLUSTER_RETURN.load_next = load_next_c;
    end
    always_ff @(posedge clk or negedge arst_n) begin
      if (~arst_n) begin
        field_storage.snitch_cluster_return[i0].SNITCH_CLUSTER_RETURN.value <= 32'h0;
      end else begin
        if (field_combo.snitch_cluster_return[i0].SNITCH_CLUSTER_RETURN.load_next) begin
          field_storage.snitch_cluster_return[i0].SNITCH_CLUSTER_RETURN.value <= field_combo.snitch_cluster_return[i0].SNITCH_CLUSTER_RETURN.next;
        end
      end
    end
    assign hwif_out.snitch_cluster_return[i0].SNITCH_CLUSTER_RETURN.value = field_storage.snitch_cluster_return[i0].SNITCH_CLUSTER_RETURN.value;
  end
  for (genvar i0 = 0; i0 < 5; i0++) begin
    // Field: chimera_regs.reset_cluster[].RESET_CLUSTER
    always_comb begin
      automatic logic [0:0] next_c;
      automatic logic       load_next_c;
      next_c      = field_storage.reset_cluster[i0].RESET_CLUSTER.value;
      load_next_c = '0;
      if (decoded_reg_strb.reset_cluster[i0] && decoded_req_is_wr) begin  // SW write
        next_c = (field_storage.reset_cluster[i0].RESET_CLUSTER.value & ~decoded_wr_biten[0:0]) | (decoded_wr_data[0:0] & decoded_wr_biten[0:0]);
        load_next_c = '1;
      end
      field_combo.reset_cluster[i0].RESET_CLUSTER.next      = next_c;
      field_combo.reset_cluster[i0].RESET_CLUSTER.load_next = load_next_c;
    end
    always_ff @(posedge clk or negedge arst_n) begin
      if (~arst_n) begin
        field_storage.reset_cluster[i0].RESET_CLUSTER.value <= 1'h1;
      end else begin
        if (field_combo.reset_cluster[i0].RESET_CLUSTER.load_next) begin
          field_storage.reset_cluster[i0].RESET_CLUSTER.value <= field_combo.reset_cluster[i0].RESET_CLUSTER.next;
        end
      end
    end
    assign hwif_out.reset_cluster[i0].RESET_CLUSTER.value = field_storage.reset_cluster[i0].RESET_CLUSTER.value;
  end
  for (genvar i0 = 0; i0 < 5; i0++) begin
    // Field: chimera_regs.cluster_clk_gate_en[].CLUSTER_CLK_GATE_EN
    always_comb begin
      automatic logic [0:0] next_c;
      automatic logic       load_next_c;
      next_c      = field_storage.cluster_clk_gate_en[i0].CLUSTER_CLK_GATE_EN.value;
      load_next_c = '0;
      if (decoded_reg_strb.cluster_clk_gate_en[i0] && decoded_req_is_wr) begin  // SW write
        next_c = (field_storage.cluster_clk_gate_en[i0].CLUSTER_CLK_GATE_EN.value & ~decoded_wr_biten[0:0]) | (decoded_wr_data[0:0] & decoded_wr_biten[0:0]);
        load_next_c = '1;
      end
      field_combo.cluster_clk_gate_en[i0].CLUSTER_CLK_GATE_EN.next      = next_c;
      field_combo.cluster_clk_gate_en[i0].CLUSTER_CLK_GATE_EN.load_next = load_next_c;
    end
    always_ff @(posedge clk or negedge arst_n) begin
      if (~arst_n) begin
        field_storage.cluster_clk_gate_en[i0].CLUSTER_CLK_GATE_EN.value <= 1'h1;
      end else begin
        if (field_combo.cluster_clk_gate_en[i0].CLUSTER_CLK_GATE_EN.load_next) begin
          field_storage.cluster_clk_gate_en[i0].CLUSTER_CLK_GATE_EN.value <= field_combo.cluster_clk_gate_en[i0].CLUSTER_CLK_GATE_EN.next;
        end
      end
    end
    assign hwif_out.cluster_clk_gate_en[i0].CLUSTER_CLK_GATE_EN.value = field_storage.cluster_clk_gate_en[i0].CLUSTER_CLK_GATE_EN.value;
  end
  for (genvar i0 = 0; i0 < 5; i0++) begin
    // Field: chimera_regs.wide_mem_cluster_bypass[].WIDE_MEM_CLUSTER_BYPASS
    always_comb begin
      automatic logic [0:0] next_c;
      automatic logic       load_next_c;
      next_c      = field_storage.wide_mem_cluster_bypass[i0].WIDE_MEM_CLUSTER_BYPASS.value;
      load_next_c = '0;
      if (decoded_reg_strb.wide_mem_cluster_bypass[i0] && decoded_req_is_wr) begin  // SW write
        next_c = (field_storage.wide_mem_cluster_bypass[i0].WIDE_MEM_CLUSTER_BYPASS.value & ~decoded_wr_biten[0:0]) | (decoded_wr_data[0:0] & decoded_wr_biten[0:0]);
        load_next_c = '1;
      end
      field_combo.wide_mem_cluster_bypass[i0].WIDE_MEM_CLUSTER_BYPASS.next      = next_c;
      field_combo.wide_mem_cluster_bypass[i0].WIDE_MEM_CLUSTER_BYPASS.load_next = load_next_c;
    end
    always_ff @(posedge clk or negedge arst_n) begin
      if (~arst_n) begin
        field_storage.wide_mem_cluster_bypass[i0].WIDE_MEM_CLUSTER_BYPASS.value <= 1'h0;
      end else begin
        if (field_combo.wide_mem_cluster_bypass[i0].WIDE_MEM_CLUSTER_BYPASS.load_next) begin
          field_storage.wide_mem_cluster_bypass[i0].WIDE_MEM_CLUSTER_BYPASS.value <= field_combo.wide_mem_cluster_bypass[i0].WIDE_MEM_CLUSTER_BYPASS.next;
        end
      end
    end
    assign hwif_out.wide_mem_cluster_bypass[i0].WIDE_MEM_CLUSTER_BYPASS.value = field_storage.wide_mem_cluster_bypass[i0].WIDE_MEM_CLUSTER_BYPASS.value;
  end
  for (genvar i0 = 0; i0 < 5; i0++) begin
    // Field: chimera_regs.cluster_busy[].CLUSTER_BUSY
    always_comb begin
      automatic logic [0:0] next_c;
      automatic logic       load_next_c;
      next_c      = field_storage.cluster_busy[i0].CLUSTER_BUSY.value;
      load_next_c = '0;
      if (decoded_reg_strb.cluster_busy[i0] && decoded_req_is_wr) begin  // SW write
        next_c = (field_storage.cluster_busy[i0].CLUSTER_BUSY.value & ~decoded_wr_biten[0:0]) | (decoded_wr_data[0:0] & decoded_wr_biten[0:0]);
        load_next_c = '1;
      end
      field_combo.cluster_busy[i0].CLUSTER_BUSY.next      = next_c;
      field_combo.cluster_busy[i0].CLUSTER_BUSY.load_next = load_next_c;
    end
    always_ff @(posedge clk or negedge arst_n) begin
      if (~arst_n) begin
        field_storage.cluster_busy[i0].CLUSTER_BUSY.value <= 1'h0;
      end else begin
        if (field_combo.cluster_busy[i0].CLUSTER_BUSY.load_next) begin
          field_storage.cluster_busy[i0].CLUSTER_BUSY.value <= field_combo.cluster_busy[i0].CLUSTER_BUSY.next;
        end
      end
    end
    assign hwif_out.cluster_busy[i0].CLUSTER_BUSY.value = field_storage.cluster_busy[i0].CLUSTER_BUSY.value;
  end

  //--------------------------------------------------------------------------
  // Write response
  //--------------------------------------------------------------------------
  assign cpuif_wr_ack = decoded_req & decoded_req_is_wr;
  // Writes are always granted with no error response
  assign cpuif_wr_err = '0;

  //--------------------------------------------------------------------------
  // Readback
  //--------------------------------------------------------------------------

  logic        readback_err;
  logic        readback_done;
  logic [31:0] readback_data;

  // Assign readback values to a flattened array
  logic [31:0] readback_array[28];
  assign readback_array[0][31:0] = (decoded_reg_strb.snitch_boot_addr && !decoded_req_is_wr) ? field_storage.snitch_boot_addr.SNITCH_BOOT_ADDR.value : '0;
  assign readback_array[1][31:0] = (decoded_reg_strb.snitch_configurable_boot_addr && !decoded_req_is_wr) ? field_storage.snitch_configurable_boot_addr.SNITCH_CONFIGURABLE_BOOT_ADDR.value : '0;
  assign readback_array[2][31:0] = (decoded_reg_strb.snitch_intr_handler_addr && !decoded_req_is_wr) ? field_storage.snitch_intr_handler_addr.SNITCH_INTR_HANDLER_ADDR.value : '0;
  for (genvar i0 = 0; i0 < 5; i0++) begin
    assign readback_array[i0 * 1 + 3][31:0] = (decoded_reg_strb.snitch_cluster_return[i0] && !decoded_req_is_wr) ? field_storage.snitch_cluster_return[i0].SNITCH_CLUSTER_RETURN.value : '0;
  end
  for (genvar i0 = 0; i0 < 5; i0++) begin
    assign readback_array[i0 * 1 + 8][0:0] = (decoded_reg_strb.reset_cluster[i0] && !decoded_req_is_wr) ? field_storage.reset_cluster[i0].RESET_CLUSTER.value : '0;
    assign readback_array[i0*1+8][31:1] = '0;
  end
  for (genvar i0 = 0; i0 < 5; i0++) begin
    assign readback_array[i0 * 1 + 13][0:0] = (decoded_reg_strb.cluster_clk_gate_en[i0] && !decoded_req_is_wr) ? field_storage.cluster_clk_gate_en[i0].CLUSTER_CLK_GATE_EN.value : '0;
    assign readback_array[i0*1+13][31:1] = '0;
  end
  for (genvar i0 = 0; i0 < 5; i0++) begin
    assign readback_array[i0 * 1 + 18][0:0] = (decoded_reg_strb.wide_mem_cluster_bypass[i0] && !decoded_req_is_wr) ? field_storage.wide_mem_cluster_bypass[i0].WIDE_MEM_CLUSTER_BYPASS.value : '0;
    assign readback_array[i0*1+18][31:1] = '0;
  end
  for (genvar i0 = 0; i0 < 5; i0++) begin
    assign readback_array[i0 * 1 + 23][0:0] = (decoded_reg_strb.cluster_busy[i0] && !decoded_req_is_wr) ? field_storage.cluster_busy[i0].CLUSTER_BUSY.value : '0;
    assign readback_array[i0*1+23][31:1] = '0;
  end

  // Reduce the array
  always_comb begin
    automatic logic [31:0] readback_data_var;
    readback_done     = decoded_req & ~decoded_req_is_wr;
    readback_err      = '0;
    readback_data_var = '0;
    for (int i = 0; i < 28; i++) readback_data_var |= readback_array[i];
    readback_data = readback_data_var;
  end

  assign cpuif_rd_ack  = readback_done;
  assign cpuif_rd_data = readback_data;
  assign cpuif_rd_err  = readback_err;
endmodule
